{
  "timestamp": "2025-10-24T16:25:00.351803Z",
  "input_project_excerpt": "Detecting and Characterizing Group Interactions Using 3D Spatial Data to Enhance Human-Robot Engagement. As robotic systems become increasingly integrated into human environments, it is critical to develop advanced methods that enable them to interpret and respond to complex social dynamics. This work combines a YOLOv8-based human pose estimation approach with 3D Mean Shift clustering for the detection and analysis of behavioral characteristics in social groups, using 3D point clouds generated by the Intel® RealSense™D435i as a cost-effective alternative to LiDAR systems. Our proposed method a...",
  "parameters": {
    "max_results_openalex": 50,
    "max_results_patents": 100,
    "embedder_name": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
    "top_k": 10,
    "novelty_threshold": 0.8,
    "borderline_band": [
      0.5,
      0.8
    ],
    "obvious_mean_threshold": 0.6,
    "multi_ref_obvious_threshold": 0.55,
    "min_refs_for_obviousness": 3
  },
  "modules": {
    "1_novedad": {
      "status": "No novedoso (colisión probable)",
      "risk": "ALTO",
      "max_similarity": 0.9248,
      "novelty_score": 0.0752,
      "thresholds": {
        "no_novedad_si_sim_ge": 0.8,
        "zona_gris": [
          0.5,
          0.8
        ]
      }
    },
    "2_nivel_inventivo": {
      "status": "Riesgo intermedio (posible obviedad)",
      "risk": "MEDIO",
      "mean_topk_similarity": 0.5981,
      "strong_ref_count": 5,
      "unique_cpc_groups": [],
      "explanation": "Promedio de similitudes y diversidad CPC considerados."
    },
    "3_aplicacion_industrial": {
      "status": "Revisar (evidencia limitada)",
      "evidence_keywords": [],
      "top_cpc_sections": [],
      "top_cpc_groups": [],
      "semantic_labels_suggested": []
    }
  },
  "top_references": [
    {
      "source": "openalex",
      "id": "https://openalex.org/W4412822486",
      "title": "Detecting and Characterizing Group Interactions Using 3D Spatial Data to Enhance Human-Robot Engagement",
      "date": "2025-06-01",
      "url": "https://doi.org/10.1145/3747393.3747398",
      "score": 0.9248,
      "cpc_sections": [],
      "cpc_groups": [],
      "by": "Steven Araujo Moran (ORCID: https://orcid.org/0009-0005-9635-7307) - ESPOL Polytechnic University, Guayaquil, Ecuador, K. Muñoz - ESPOL Polytechnic University, Guayaquil, Ecuador, L. SALAZAR - ESPOL Polytechnic University, Guayaquil, Ecuador, Boris X. Vintimilla (ORCID: https://orcid.org/0000-0001-8904-0209) - ESPOL Polytechnic University, Guayaquil, Ecuador",
      "abstract": ""
    },
    {
      "source": "openalex",
      "id": "https://openalex.org/W2617211984",
      "title": "Social Eye Gaze in Human-Robot Interaction: A Review",
      "date": "2017-03-01",
      "url": "https://doi.org/10.5898/jhri.6.1.admoni",
      "score": 0.678,
      "cpc_sections": [],
      "cpc_groups": [],
      "by": "Henny Admoni (ORCID: https://orcid.org/0000-0003-1796-2196) - Carnegie Mellon University, Brian Scassellati (ORCID: https://orcid.org/0000-0002-7671-7759) - Yale University",
      "abstract": "This article reviews the state of the art in social eye gaze for human-robot interaction (HRI). It establishes three categories of gaze research in HRI, defined by differences in goals and methods: a human-centered approach, which focuses on people's responses to gaze; a design-centered approach, which addresses the features of robot gaze behavior and appearance that improve interaction; and a technology-centered approach, which is concentrated on the computational tools for implementing social eye gaze in robots. This paper begins with background information about gaze research in HRI and ends with a set of open questions."
    },
    {
      "source": "openalex",
      "id": "https://openalex.org/W2099019320",
      "title": "A survey of socially interactive robots",
      "date": "2003-02-28",
      "url": "https://doi.org/10.1016/s0921-8890(02)00372-x",
      "score": 0.6689,
      "cpc_sections": [],
      "cpc_groups": [],
      "by": "Terrence Fong - Institut de production et robotique, Ecole Polytechnique Fédérale de Lausanne, CH-1015 Lausanne, Switzerland, Illah Nourbakhsh - The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA 15213, USA, Kerstin Dautenhahn (ORCID: https://orcid.org/0000-0002-9263-3897) - Department of Computer Science, The University of Hertfordshire, College Lane, Hatfield, Hertfordshire AL10 9AB, UK",
      "abstract": ""
    },
    {
      "source": "openalex",
      "id": "https://openalex.org/W2763083925",
      "title": "Robots As Intentional Agents: Using Neuroscientific Methods to Make Robots Appear More Social",
      "date": "2017-10-04",
      "url": "https://doi.org/10.3389/fpsyg.2017.01663",
      "score": 0.6491,
      "cpc_sections": [],
      "cpc_groups": [],
      "by": "Eva Wiese (ORCID: https://orcid.org/0000-0002-0322-1250) - Department of Psychology, George Mason University, Fairfax, VA, United States, Giorgio Metta (ORCID: https://orcid.org/0000-0003-0459-4769) - Istituto Italiano di Tecnologia, Genoa, Italy, Agnieszka Wykowska (ORCID: https://orcid.org/0000-0003-3323-7357) - Istituto Italiano di Tecnologia, Genoa, Italy",
      "abstract": "Robots are increasingly envisaged as our future cohabitants. However, while considerable progress has been made in recent years in terms of their technological realization, the ability of robots to interact with humans in an intuitive and social way is still quite limited. An important challenge for social robotics is to determine how to design robots that can perceive the user's needs, feelings, and intentions, and adapt to users over a broad range of cognitive abilities. It is conceivable that if robots were able to adequately demonstrate these skills, humans would eventually accept them as social companions. We argue that the best way to achieve this is using a systematic experimental approach based on behavioral and physiological neuroscience methods such as motion/eye-tracking, electroencephalography, or functional near-infrared spectroscopy embedded in interactive human-robot paradigms. This approach requires understanding how humans interact with each other, how they perform tasks together and how they develop feelings of social connection over time, and using these insights to formulate design principles that make social robots attuned to the workings of the human brain. In this review, we put forward the argument that the likelihood of artificial agents being perceived as social companions can be increased by designing them in a way that they are perceived as intentional agents that activate areas in the human brain involved in social-cognitive processing. We first review literature related to social-cognitive processes and mechanisms involved in human-human interactions, and highlight the importance of perceiving others as intentional agents to activate these social brain areas. We then discuss how attribution of intentionality can positively affect human-robot interaction by (a) fostering feelings of social connection, empathy and prosociality, and by (b) enhancing performance on joint human-robot tasks. Lastly, we describe circumstances under which attribution of intentionality to robot agents might be disadvantageous, and discuss challenges associated with designing social robots that are inspired by neuroscientific principles."
    },
    {
      "source": "openalex",
      "id": "https://openalex.org/W2180635266",
      "title": "A Review of Human Activity Recognition Methods",
      "date": "2015-11-16",
      "url": "https://doi.org/10.3389/frobt.2015.00028",
      "score": 0.6234,
      "cpc_sections": [],
      "cpc_groups": [],
      "by": "Michalis Vrigkas (ORCID: https://orcid.org/0000-0001-5888-6949) - Department of Computer Science and Engineering, University of Ioannina, Ioannina, Greece, Christophoros Nikou (ORCID: https://orcid.org/0000-0003-1388-6915) - Department of Computer Science and Engineering, University of Ioannina, Ioannina, Greece, Ioannis A. Kakadiaris (ORCID: https://orcid.org/0000-0002-0591-1079) - Computational Biomedicine Laboratory, Department of Computer Science, University of Houston, Houston, TX, USA",
      "abstract": "Recognizing human activities from video sequences or still images is a challenging task due to problems such as background clutter, partial occlusion, changes in scale, viewpoint, lighting, and appearance. Many applications, including video surveillance systems, human-computer interaction, and robotics for human behavior characterization, require a multiple activity recognition system. In this work, we provide a detailed review of recent and state-of-the-art research advances in the field of human activity classification. We propose a categorization of human activity methodologies and discuss their advantages and limitations. In particular, we divide human activity classification methods into two large categories according to whether they use data from different modalities or not. Then, each of these categories is further analyzed into sub-categories, which reflect how they model human activities and what type of activities they are interested in. Moreover, we provide a comprehensive analysis of the existing, publicly available human activity classification datasets and examine the requirements for an ideal human activity recognition dataset. Finally, we report the characteristics of future research directions and present some open issues on human activity recognition."
    },
    {
      "source": "openalex",
      "id": "https://openalex.org/W4388639388",
      "title": "Artificial Intelligence Meets Flexible Sensors: Emerging Smart Flexible Sensing Systems Driven by Machine Learning and Artificial Synapses",
      "date": "2023-11-13",
      "url": "https://doi.org/10.1007/s40820-023-01235-x",
      "score": 0.5456,
      "cpc_sections": [],
      "cpc_groups": [],
      "by": "Tianming Sun - College of Materials Science and Engineering, Shanxi Province, Taiyuan University of Technology, Taiyuan, 030024, People's Republic of China., Bin Feng (ORCID: https://orcid.org/0000-0001-5055-9521) - Department of Mechanical Engineering, State Key Laboratory of Tribology in Advanced Equipment, Key Laboratory for Advanced Manufacturing by Materials Processing Technology, Ministry of Education of PR China, Tsinghua University, Beijing, 100084, People's Republic of China., Jinpeng Huo (ORCID: https://orcid.org/0000-0001-7858-0648) - Department of Mechanical Engineering, State Key Laboratory of Tribology in Advanced Equipment, Key Laboratory for Advanced Manufacturing by Materials Processing Technology, Ministry of Education of PR China, Tsinghua University, Beijing, 100084, People's Republic of China., Yu Xiao (ORCID: https://orcid.org/0000-0002-3849-6895) - Department of Mechanical Engineering, State Key Laboratory of Tribology in Advanced Equipment, Key Laboratory for Advanced Manufacturing by Materials Processing Technology, Ministry of Education of PR China, Tsinghua University, Beijing, 100084, People's Republic of China., Wengan Wang (ORCID: https://orcid.org/0000-0002-4235-3686) - Department of Mechanical Engineering, State Key Laboratory of Tribology in Advanced Equipment, Key Laboratory for Advanced Manufacturing by Materials Processing Technology, Ministry of Education of PR China, Tsinghua University, Beijing, 100084, People's Republic of China., Jin Peng (ORCID: https://orcid.org/0000-0003-0611-946X) - Department of Mechanical Engineering, State Key Laboratory of Tribology in Advanced Equipment, Key Laboratory for Advanced Manufacturing by Materials Processing Technology, Ministry of Education of PR China, Tsinghua University, Beijing, 100084, People's Republic of China., Zehua Li (ORCID: https://orcid.org/0009-0000-0120-0256) - Department of Mechanical Engineering, State Key Laboratory of Tribology in Advanced Equipment, Key Laboratory for Advanced Manufacturing by Materials Processing Technology, Ministry of Education of PR China, Tsinghua University, Beijing, 100084, People's Republic of China., Chengjie Du (ORCID: https://orcid.org/0000-0001-7286-9002) - Department of Mechanical Engineering, State Key Laboratory of Tribology in Advanced Equipment, Key Laboratory for Advanced Manufacturing by Materials Processing Technology, Ministry of Education of PR China, Tsinghua University, Beijing, 100084, People's Republic of China., Wenxian Wang - College of Materials Science and Engineering, Shanxi Province, Taiyuan University of Technology, Taiyuan, 030024, People's Republic of China. wangwenxian@tyut.edu.cn., Guisheng Zou - Department of Mechanical Engineering, State Key Laboratory of Tribology in Advanced Equipment, Key Laboratory for Advanced Manufacturing by Materials Processing Technology, Ministry of Education of PR China, Tsinghua University, Beijing, 100084, People's Republic of China. zougsh@tsinghua.edu.cn., Lei Liu (ORCID: https://orcid.org/0000-0002-3368-5136) - Department of Mechanical Engineering, State Key Laboratory of Tribology in Advanced Equipment, Key Laboratory for Advanced Manufacturing by Materials Processing Technology, Ministry of Education of PR China, Tsinghua University, Beijing, 100084, People's Republic of China. liulei@tsinghua.edu.cn.",
      "abstract": "The recent wave of the artificial intelligence (AI) revolution has aroused unprecedented interest in the intelligentialize of human society. As an essential component that bridges the physical world and digital signals, flexible sensors are evolving from a single sensing element to a smarter system, which is capable of highly efficient acquisition, analysis, and even perception of vast, multifaceted data. While challenging from a manual perspective, the development of intelligent flexible sensing has been remarkably facilitated owing to the rapid advances of brain-inspired AI innovations from both the algorithm (machine learning) and the framework (artificial synapses) level. This review presents the recent progress of the emerging AI-driven, intelligent flexible sensing systems. The basic concept of machine learning and artificial synapses are introduced. The new enabling features induced by the fusion of AI and flexible sensing are comprehensively reviewed, which significantly advances the applications such as flexible sensory systems, soft/humanoid robotics, and human activity monitoring. As two of the most profound innovations in the twenty-first century, the deep incorporation of flexible sensing and AI technology holds tremendous potential for creating a smarter world for human beings."
    },
    {
      "source": "openalex",
      "id": "https://openalex.org/W2076748073",
      "title": "A Review of Mobile Robotic Telepresence",
      "date": "2013-01-01",
      "url": "https://doi.org/10.1155/2013/902316",
      "score": 0.4924,
      "cpc_sections": [],
      "cpc_groups": [],
      "by": "Annica Kristoffersson (ORCID: https://orcid.org/0000-0002-4368-4751) - Center of Applied Autonomous Sensor Systems, Örebro University, Fakultetsgatan 1, 70182 Örebro, Sweden, Silvia Coradeschi - Center of Applied Autonomous Sensor Systems, Örebro University, Fakultetsgatan 1, 70182 Örebro, Sweden, Amy Loutfi (ORCID: https://orcid.org/0000-0002-3122-693X) - Center of Applied Autonomous Sensor Systems, Örebro University, Fakultetsgatan 1, 70182 Örebro, Sweden",
      "abstract": "Mobile robotic telepresence (MRP) systems incorporate video conferencing equipment onto mobile robot devices which can be steered from remote locations. These systems, which are primarily used in the context of promoting social interaction between people, are becoming increasingly popular within certain application domains such as health care environments, independent living for the elderly, and office environments. In this paper, an overview of the various systems, application areas, and challenges found in the literature concerning mobile robotic telepresence is provided. The survey also proposes a set terminology for the field as there is currently a lack of standard terms for the different concepts related to MRP systems. Further, this paper provides an outlook on the various research directions for developing and enhancing mobile robotic telepresence systems per se, as well as evaluating the interaction in laboratory and field settings. Finally, the survey outlines a number of design implications for the future of mobile robotic telepresence systems for social interaction."
    },
    {
      "source": "openalex",
      "id": "https://openalex.org/W2259092398",
      "title": "Toward a Social Psychophysics of Face Communication",
      "date": "2017-01-03",
      "url": "https://doi.org/10.1146/annurev-psych-010416-044242",
      "score": 0.4757,
      "cpc_sections": [],
      "cpc_groups": [],
      "by": "Rachael E. Jack (ORCID: https://orcid.org/0000-0003-3687-0799) - Institute of Neuroscience and Psychology, and School of Psychology, University of Glasgow, Glasgow G12 8QB United Kingdom;, Philippe G. Schyns (ORCID: https://orcid.org/0000-0002-8542-7489) - Institute of Neuroscience and Psychology, and School of Psychology, University of Glasgow, Glasgow G12 8QB United Kingdom;",
      "abstract": "As a highly social species, humans are equipped with a powerful tool for social communication—the face. Although seemingly simple, the human face can elicit multiple social perceptions due to the rich variations of its movements, morphology, and complexion. Consequently, identifying precisely what face information elicits different social perceptions is a complex empirical challenge that has largely remained beyond the reach of traditional methods. In the past decade, the emerging field of social psychophysics has developed new methods to address this challenge, with the potential to transfer psychophysical laws of social perception to the digital economy via avatars and social robots. At this exciting juncture, it is timely to review these new methodological developments. In this article, we introduce and review the foundational methodological developments of social psychophysics, present work done in the past decade that has advanced understanding of the face as a tool for social communication, and discuss the major challenges that lie ahead."
    },
    {
      "source": "openalex",
      "id": "https://openalex.org/W2787690100",
      "title": "The grand challenges of <i>Science Robotics</i>",
      "date": "2018-01-31",
      "url": "https://doi.org/10.1126/scirobotics.aar7650",
      "score": 0.4616,
      "cpc_sections": [],
      "cpc_groups": [],
      "by": "Guang‐Zhong Yang (ORCID: https://orcid.org/0000-0003-4060-4020) - Hamlyn Centre for Robotic Surgery, Imperial College London, London, UK., Jim Bellingham - Center for Marine Robotics, Woods Hole Oceanographic Institution, Woods Hole, MA 02543, USA., Pierre E. Dupont (ORCID: https://orcid.org/0000-0001-7294-640X) - Department of Cardiovascular Surgery, Boston Children's Hospital, Harvard Medical School, Boston, MA 02115, USA., Peer Fischer (ORCID: https://orcid.org/0000-0002-8600-5958) - Micro, Nano, and Molecular Systems Laboratory, Max Planck Institute for Intelligent Systems, Stuttgart, Germany., Luciano Floridi (ORCID: https://orcid.org/0000-0002-5444-2280) - Centre for Practical Ethics, Faculty of Philosophy, University of Oxford, Oxford, UK., Robert J. Full (ORCID: https://orcid.org/0000-0001-8435-5279) - Department of Integrative Biology, University of California, Berkeley, Berkeley, CA 94720, USA., Neil Jacobstein (ORCID: https://orcid.org/0000-0002-3539-4009) - Singularity University, NASA Research Park, Moffett Field, CA 94035, USA., Vijay Kumar - Department of Mechanical Engineering and Applied Mechanics, University of Pennsylvania, Philadelphia, PA 19104, USA., Marcia McNutt (ORCID: https://orcid.org/0000-0003-0117-7716) - National Academy of Sciences, Washington, DC 20418, USA., Robert Merrifield - Hamlyn Centre for Robotic Surgery, Imperial College London, London, UK., Bradley J. Nelson (ORCID: https://orcid.org/0000-0001-9070-6987) - Institute of Robotics and Intelligent Systems, Department of Mechanical and Process Engineering, ETH Zürich, Zurich, Switzerland., Brian Scassellati (ORCID: https://orcid.org/0000-0002-7671-7759) - Department of Computer Science, Yale University, New Haven, CT 06520, USA., Mariarosaria Taddeo (ORCID: https://orcid.org/0000-0002-1181-649X) - Digital Ethics Lab, Oxford Internet Institute, University of Oxford, Oxford, UK., Russell H. Taylor (ORCID: https://orcid.org/0000-0001-6272-1100) - Department of Computer Science, Johns Hopkins University, Baltimore, MD 21218, USA., Manuela Veloso (ORCID: https://orcid.org/0000-0001-6738-238X) - Machine Learning Department, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA 15213, USA., Zhong Lin Wang (ORCID: https://orcid.org/0000-0002-5530-0380) - School of Materials Science and Engineering, Georgia Institute of Technology, Atlanta, GA 30332, USA., Robert J. Wood (ORCID: https://orcid.org/0000-0001-7969-038X) - John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA 02138, USA.",
      "abstract": "These 10 grand challenges may have major breakthroughs, research, and/or socioeconomic impacts in the next 5 to 10 years."
    },
    {
      "source": "openalex",
      "id": "https://openalex.org/W2949263306",
      "title": "Noninvasive neuroimaging enhances continuous neural tracking for robotic device control",
      "date": "2019-06-19",
      "url": "https://doi.org/10.1126/scirobotics.aaw6844",
      "score": 0.4614,
      "cpc_sections": [],
      "cpc_groups": [],
      "by": "Bradley J. Edelman (ORCID: https://orcid.org/0000-0002-7502-9620) - Department of Biomedical Engineering, University of Minnesota, Minneapolis, MN 55455, USA., Jianjun Meng (ORCID: https://orcid.org/0000-0003-0813-652X) - Department of Biomedical Engineering, Carnegie Mellon University, Pittsburgh, PA 15213, USA., Daniel Suma (ORCID: https://orcid.org/0000-0001-9570-311X) - Department of Biomedical Engineering, Carnegie Mellon University, Pittsburgh, PA 15213, USA., Claire A. Zurn (ORCID: https://orcid.org/0000-0001-8527-1325) - Department of Biomedical Engineering, University of Minnesota, Minneapolis, MN 55455, USA., Eric K. Nagarajan (ORCID: https://orcid.org/0000-0002-4135-9875) - Department of Neuroscience, University of Minnesota, Minneapolis, MN 55455, USA., Bryan Baxter (ORCID: https://orcid.org/0000-0003-3056-0204) - Department of Biomedical Engineering, University of Minnesota, Minneapolis, MN 55455, USA., Christopher C. Cline (ORCID: https://orcid.org/0000-0003-1442-8641) - Department of Biomedical Engineering, University of Minnesota, Minneapolis, MN 55455, USA., Bin He (ORCID: https://orcid.org/0000-0003-2944-8602) - Department of Biomedical Engineering, Carnegie Mellon University, Pittsburgh, PA 15213, USA.",
      "abstract": "Noninvasive neuroimaging and increased user engagement improve EEG-based neural decoding and facilitate real-time 2D robotic device control."
    }
  ]
}